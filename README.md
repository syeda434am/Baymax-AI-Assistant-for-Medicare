# Baymax AI Medicare Assistant

## Overview
Baymax is an intelligent AI-powered medical document retrieval and query assistant designed to help users extract and understand information from medical PDF documents using advanced natural language processing.

## Project Architecture
- **Frontend**: Streamlit-based interactive web interface
- **Backend**: Modular Python implementation with:
  - Document loading
  - Vector embeddings
  - Retrieval-based Question Answering
- **Model**: Ollama with Medllama2 LLM
- **Vector Database**: FAISS for efficient document retrieval

## Features
- ğŸ“„ Load and process medical PDF documents
- ğŸ” Semantic search across document contents
- ğŸ’¬ Interactive chat interface
- ğŸ§  Retrieval-augmented generation using Ollama
- ğŸ“Š Source document tracing

## Prerequisites
- Python 3.8+
- Ollama
- Git

## Technology Stack
- Langchain
- Streamlit
- Ollama
- HuggingFace Embeddings
- FAISS Vector Store

## Installation Steps

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/baymax-ai-assistant.git
cd baymax-ai-assistant
```

### 2. Install Ollama
- Download from [Ollama Official Website](https://ollama.com/)
- Pull Medllama2 Model
```bash
ollama pull medllama2
```

### 3. Create Virtual Environment
```bash
# On Windows
python -m venv venv
venv\Scripts\activate

# On macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```

### 5. Prepare Vector Database
```bash
python backend/prepare_db.py
```

### 6. Run the Application
```bash
streamlit run frontend/baymax.py
```

## Project Structure
```
baymax-ai-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ prepare_db.py
â”‚   â””â”€â”€ retrieval_qa.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ baymax.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (your medical PDF files)
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Configuration
- Modify `backend/retrieval_qa.py` to change:
  - LLM model
  - Prompt template
  - Retrieval parameters

## Adding Documents
- Place medical PDFs in the `data/` directory
- Run `prepare_db.py` to update vector database

## Troubleshooting
- Ensure Ollama is running
- Check PDF file permissions
- Verify virtual environment activation
- Install missing dependencies

## License
[This project is licensed under the Apache License Version 2.0 - see the LICENSE file for details.]

## Acknowledgements
- Ollama API
- FAISS
- Langchain
- Streamlit
- Medllama2
```